{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "    # file_path = 'data/TinyStories-valid.txt'\n",
    "    # tokenizer_path = \"tokenizer.model\"\n",
    "    # frequency_cutoff=25\n",
    "\n",
    "    batch_size: int = 32\n",
    "    context_window: int = 16\n",
    "    # early_stopping_criteria :int = 5\n",
    "    # learning_rate: float = 0.001\n",
    "    n_layers: int = 18\n",
    "    n_heads: int = 8\n",
    "    vocab_size: int = -1  # set after tokenizer is loaded\n",
    "    d_model: int = 128\n",
    "    epochs: int = 10000\n",
    "    log_interval: int = 10\n",
    "    max_seq_len: int = 512\n",
    "    ffn_dim_multiplier: Optional[int] = None\n",
    "    multiple_of: int = 256\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # cuda: bool = True\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        # print all the attributes of the class and theirn values\n",
    "        return '\\n'.join([f'{k} : {v}' for k, v in self.__dict__.items()])\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return self.__repr__()\n",
    "Args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_size : 32\n",
       "context_window : 16\n",
       "n_layers : 18\n",
       "n_heads : 8\n",
       "vocab_size : -1\n",
       "d_model : 128\n",
       "epochs : 10000\n",
       "log_interval : 10\n",
       "max_seq_len : 512\n",
       "ffn_dim_multiplier : None\n",
       "multiple_of : 256\n",
       "device : cuda"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Spot. Spot saw the shiny car \n"
     ]
    }
   ],
   "source": [
    "lines = open('./data/TinyStories-valid.txt', encoding=\"utf8\").read()\n",
    "# lines = lines[:1115394]\n",
    "\n",
    "vocab = sorted(list(set(lines)))\n",
    "itos = {i:ch for i, ch in enumerate(vocab)}\n",
    "stoi = {ch:i for i, ch in enumerate(vocab)}\n",
    "\n",
    "print(lines[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple tokenization by characters\n",
    "def encode(s):\n",
    "    return [stoi[ch] for ch in s]\n",
    "\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l])\n",
    "\n",
    "print('vocab size:', len(vocab))\n",
    "decode(encode(\"hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19432979])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = torch.tensor(encode(lines), dtype=torch.int8)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(data, split, batch_size, context_window, args=Args):\n",
    "    train = data[:int(.8 * len(data))]\n",
    "    val = data[int(.8 * len(data)): int(.9 * len(data))]\n",
    "    test = data[int(.9 * len(data)):]\n",
    "\n",
    "    batch_data = train\n",
    "    if split == 'val':\n",
    "        batch_data = val\n",
    "\n",
    "    if split == 'test':\n",
    "        batch_data = test\n",
    "\n",
    "    # pick random starting points\n",
    "    ix = torch.randint(0, batch_data.size(0) - context_window - 1, (batch_size,))\n",
    "    x = torch.stack([batch_data[i:i+context_window] for i in ix]).long()\n",
    "    y = torch.stack([batch_data[i+1:i+context_window+1] for i in ix]).long()\n",
    "    return x.to(device=args.device), y.to(device=args.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()  # don't compute gradients for this function\n",
    "def evaluate_loss(model, args=Args):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = []\n",
    "        for _ in range(10):\n",
    "            xb, yb = get_batches(dataset, split, args.batch_size, args.context_window, args=args)\n",
    "            _, loss = model(xb, yb)\n",
    "            losses.append(loss.item())\n",
    "        out[split] = np.mean(losses)\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SimpleBrokenModel(nn.Module):\n",
    "    def __init__(self, args=Args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "\n",
    "        self.embedding = nn.Embedding(args.vocab_size, args.d_model)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(args.d_model, args.d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(args.d_model, args.vocab_size),\n",
    "        )\n",
    "\n",
    "        print(\"model params:\", sum([m.numel() for m in self.parameters()]))\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        x = self.embedding(idx)\n",
    "        logits = self.linear(x)\n",
    "        # logits = F.softmax(a, dim=-1)\n",
    "\n",
    "        if targets is not None:\n",
    "            loss = loss = F.cross_entropy(logits.view(-1, self.args.vocab_size), targets.view(-1))\n",
    "            return logits, loss\n",
    "\n",
    "        else:\n",
    "            return logits\n",
    "\n",
    "Args.d_model = 128\n",
    "\n",
    "\n",
    "# model = SimpleBrokenModel(Args)\n",
    "# xs, ys = get_batches(dataset, 'train', Args.batch_size, Args.context_window)\n",
    "\n",
    "# logits, loss = model(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params: 41698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Codes\\Environments\\torch-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Args.vocab_size = len(vocab)\n",
    "Args.batch_size = 32\n",
    "Args.context_window = 16\n",
    "# Args.epochs = 1000\n",
    "Args.log_interval = 10\n",
    "\n",
    "model = SimpleBrokenModel(Args)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    ")\n",
    "\n",
    "def train(model, optimizer, scheduler=None, args=Args, print_logs=False):\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "    for epoch in range(args.epochs):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        xs, ys = get_batches(dataset, 'train', args.batch_size, args.context_window)\n",
    "        # xs = xs.to(args.device)\n",
    "        # ys = ys.to(args.device)\n",
    "        print(xs.device)\n",
    "        logits, loss = model(xs, targets=ys)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        if epoch % args.log_interval == 0:\n",
    "            batch_time = time.time() - start_time\n",
    "            x = evaluate_loss(model)\n",
    "            losses += [x]\n",
    "            if print_logs:\n",
    "                print(f\"Epoch {epoch} | val loss {x['val']:.3f} | Time {batch_time:.3f} | ETA in seconds {batch_time * (args['epochs'] - epoch)/args['log_interval'] :.3f}\")\n",
    "            start_time = time.time()\n",
    "\n",
    "            if scheduler:\n",
    "                print(\"lr: \", scheduler.get_lr())\n",
    "\n",
    "    print(\"validation loss: \", losses[-1]['val'])\n",
    "    return pd.DataFrame(losses).plot()\n",
    "\n",
    "# train(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, args=Args, max_new_tokens=30):\n",
    "    idx = torch.zeros(5, 1).long()\n",
    "    for _ in range(max_new_tokens):\n",
    "        # call the model\n",
    "        logits = model(idx[:, -args.context_window:])\n",
    "        last_time_step_logits = logits[\n",
    "            :, -1, :\n",
    "        ]  # all the batches (1), last time step, all the logits\n",
    "        p = F.softmax(last_time_step_logits, dim=-1)  # softmax to get probabilities\n",
    "        idx_next = torch.multinomial(\n",
    "            p, num_samples=1\n",
    "        )  # sample from the distribution to get the next token\n",
    "        idx = torch.cat([idx, idx_next], dim=-1)  # append to the sequence\n",
    "    return [decode(x) for x in idx.tolist()]\n",
    "\n",
    "# generate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMS-Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The OG RMS Norm form the llama inference repo \n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim:int, eps:float = 1e-8):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "    \n",
    "    def _norm(self, x:torch.Tensor):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True))#+self.eps)\n",
    "    \n",
    "    def forward(self, x:torch.Tensor):\n",
    "        # print(self.weight.shape, x.shape, self._norm(x.float()).shape)\n",
    "        return self.weight * self._norm(x.float()).type_as(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROPE -> Rotary Positional Embeddings Positional Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_theta_pos_frequencies(head_dim: int, seq_len: int, device: str, theta: float = 10000.0):\n",
    "    assert head_dim % 2 == 0\n",
    "\n",
    "    theta_numerator = torch.arange(0, head_dim, 2).float()\n",
    "    # shape (head_dim /2)\n",
    "    theta = 1.0 / (theta ** (theta_numerator/head_dim)).to(device)\n",
    "    m = torch.arange(seq_len, device=device)\n",
    "    # multiply each theta by each position using the outer product\n",
    "    # shape: seqlen outer prodcut head_dim / 2 -> (seq_len, head_dim /2)\n",
    "    freqs = torch.outer(m, theta).float()\n",
    "    freqs_complex = torch.polar(torch.ones_like(freqs), freqs)\n",
    "    return freqs_complex\n",
    "\n",
    "def apply_rotary_embeddings(x: torch.Tensor, freqs_complex: torch.Tensor, device: str):\n",
    "    \n",
    "    # print(f\"X-Shape: {x.shape}\")\n",
    "    # print(f\"Freqs-Shape: {freqs_complex.shape}\")\n",
    "    \n",
    "    cntxt_length = x.shape[1]\n",
    "    \n",
    "    # print(f\"Context-Length: {context_length}\")\n",
    "    \n",
    "    # (B, Seq_len, H, Head_dim) -> (B, Seq_len, H, Head_dim / 2)\n",
    "    x_complex = torch.view_as_complex(x.float().reshape(*x.shape[:-1], -1 ,2))\n",
    "    \n",
    "    # print(f\"X-Complex-Shape: {x_complex.shape}\")\n",
    "    \n",
    "    # seq_len, Head_dim/2 -> (1, Seq_len, 1, Head_dim / 2)\n",
    "    freqs_complex = freqs_complex[:cntxt_length,:]\n",
    "    \n",
    "    # print(f\"Freqs-Complex-Limited-Shape: {freqs_complex_limited.shape}\")\n",
    "    \n",
    "    freqs_complex = freqs_complex.unsqueeze(0).unsqueeze(2)\n",
    "    \n",
    "    # print(f\"Freqs-Complex-Shape-After-Unsqueeze: {freqs_complex.shape}\")\n",
    "\n",
    "    # (B, Seq_len, H, Head_dim /2) * (1, Seq_len, 1, Head_dim / 2) = (B, Seq_len, H, Head_dim / 2)\n",
    "    x_rotated = x_complex * freqs_complex\n",
    "    \n",
    "    # print(f\"X-Rotated-Shape: {x_rotated.shape}\")\n",
    "    \n",
    "    # (B,seq_len, H, Head_dim/2) -> (B, Seq_len, H, Head_dim/2, 2)\n",
    "    x_out = torch.view_as_real(x_rotated)\n",
    "\n",
    "    # print(f\"X-Out-Shape: {x_out.shape}\")\n",
    "    # print(f\"Reshape X-out to x:{x.shape}\")\n",
    "    \n",
    "    # (B, seq_len, H, Head_dim/2, 2 ) -> (B, sseq_len, H, Head_dim)\n",
    "    x_out = x_out.reshape(*x.shape)\n",
    "    return x_out.type_as(x).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = args.n_heads\n",
    "\n",
    "        self.n_rep = self.n_heads // self.n_heads\n",
    "        self.head_dim = args.d_model // args.n_heads\n",
    "\n",
    "        self.wq = nn.Linear(args.d_model, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.d_model, self.n_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.d_model, self.n_heads * self.head_dim, bias=False)\n",
    "        self.wo = nn.Linear(args.n_heads*self.head_dim, args.d_model, bias=False)\n",
    "\n",
    "\n",
    "    def forward(self, x:torch.Tensor, freqs_complex:torch.Tensor):\n",
    "        batch_size, seq_len, _ = x.shape  # (B, 1, Dim)\n",
    "\n",
    "        # (B, 1, Dim) -> (B, 1, H_Q * Head_Dim)\n",
    "        xq = self.wq(x)\n",
    "        # (B, 1, Dim) -> (B, 1, H_KV * Head_Dim)\n",
    "        xk = self.wk(x)\n",
    "        # (B, 1, Dim) -> (B, 1, H_KV * Head_Dim)\n",
    "        xv = self.wv(x)\n",
    "\n",
    "        # (B, 1, H_Q * Head_Dim) -> (B, 1, H_Q, Head_Dim)\n",
    "        xq = xq.view(batch_size, seq_len, self.n_heads, self.head_dim)\n",
    "        # (B, 1, H_KV * Head_Dim) -> (B, 1, H_KV, Head_Dim)\n",
    "        xk = xk.view(batch_size, seq_len, self.n_heads, self.head_dim)\n",
    "        # (B, 1, H_KV * Head_Dim) -> (B, 1, H_KV, Head_Dim)\n",
    "        xv = xv.view(batch_size, seq_len, self.n_heads, self.head_dim)\n",
    "        #apply rotatory embeddings to the keys and values\n",
    "        xq = apply_rotary_embeddings(xq, freqs_complex, x.device)\n",
    "        xk = apply_rotary_embeddings(xk, freqs_complex, x.device)\n",
    "\n",
    "        xq = xq.transpose(1,2)\n",
    "        keys = xk.transpose(1,2)\n",
    "        values = xv.transpose(1,2)\n",
    "\n",
    "        scores = torch.matmul(xq, keys.transpose(2,3)) / math.sqrt(self.head_dim)\n",
    "        scores =  scores.masked_fill_(torch.triu(torch.ones_like(scores), diagonal=1) == 1, float('-inf'))\n",
    "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "\n",
    "        output = torch.matmul(scores, values)\n",
    "        output = output.transpose(1,2).contiguous().view(batch_size, seq_len, -1)\n",
    "        return self.wo(output)\n",
    "\n",
    "# layer = SelfAttention(Args)\n",
    "# batch = torch.randn((Args.batch_size, Args.context_window, Args.d_model))\n",
    "# freqs_complex = precompute_theta_pos_frequencies(Args.d_model // Args.n_heads, Args.context_window, device = \"cpu\")\n",
    "# output= layer(batch, freqs_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden_dim = args.d_model * 4\n",
    "        hidden_dim = int(2 * hidden_dim / 3)\n",
    "\n",
    "        if args.ffn_dim_multiplier is not None:\n",
    "            hidden_dim = int(args.ffn_dim_multiplier * hidden_dim)\n",
    "\n",
    "        hidden_dim = args.multiple_of * ((hidden_dim + args.multiple_of - 1) // args.multiple_of)\n",
    "\n",
    "        self.w1 = nn.Linear(args.d_model, hidden_dim, bias=False)\n",
    "        self.w2 = nn.Linear(hidden_dim, args.d_model, bias=False)\n",
    "        self.w3 = nn.Linear(args.d_model, hidden_dim, bias=False)\n",
    "\n",
    "\n",
    "    def forward(self, x:torch.Tensor):\n",
    "        # return self.w2(self.w3(x) * F.silu(self.w1(x)))\n",
    "        swish = F.silu(self.w1(x))\n",
    "        x_V = self.w3(x)\n",
    "        x = swish * x_V\n",
    "        x = self.w2(x)\n",
    "        return x\n",
    "    \n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.n_heads = args.n_heads\n",
    "        self.head_dim = args.d_model // args.n_heads\n",
    "        \n",
    "        self.attention = SelfAttention(args)\n",
    "        self.feed_forward = FeedForward(args)\n",
    "\n",
    "        self.attention_norm = RMSNorm(args.d_model) #, eps =args.norm_eps)\n",
    "\n",
    "        self.ffn_norm = RMSNorm(args.d_model) #, eps=args.norm_eps)\n",
    "\n",
    "        # self.freqs_complex = precompute_theta_pos_frequencies(Args.d_model // Args.n_heads, Args.context_window, device = \"cpu\")\n",
    "    \n",
    "    def forward(self, x:torch.Tensor, freqs_complex: torch.Tensor):\n",
    "        h = x + self.attention.forward(self.attention_norm(x),  freqs_complex)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Args.vocab_size = len(vocab)\n",
    "class RopeModel(nn.Module):\n",
    "    def __init__(self, args: Args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.freqs_complex = precompute_theta_pos_frequencies(Args.d_model // Args.n_heads, Args.context_window, device = Args.device)\n",
    "        \n",
    "        #! new verison starts here\n",
    "        self.vocab_size = args.vocab_size\n",
    "        self.n_layers = args.n_layers\n",
    "        self.embedding = nn.Embedding(args.vocab_size, args.d_model)\n",
    "\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(args.n_layers):\n",
    "            self.layers.append(EncoderBlock(args))\n",
    "\n",
    "        self.norm = RMSNorm(args.d_model) #, eps=args.norm_eps)\n",
    "        self.output = nn.Linear(args.d_model, self.vocab_size , bias=False)\n",
    "\n",
    "        print(\"model params:\", sum([m.numel() for m in self.parameters()]))\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    " \n",
    "        # print(idx.shape)\n",
    "        h = self.embedding(idx)\n",
    "\n",
    "        #Consecutively apply all the encoder lauers\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, self.freqs_complex)\n",
    "        h = self.norm(h)\n",
    "        logits = self.output(h).float()\n",
    "\n",
    "        \n",
    "        # print(x.shape)\n",
    "        # one block of attention\n",
    "        # x = self.rms(x) # rms pre-normalization\n",
    "        # # print(x.shape)\n",
    "        # x = x + self.rope_attention(x, self.freqs_complex)\n",
    "        # x = self.rms(x) # rms pre-normalization\n",
    "        # x = x + self.linear(x)\n",
    "\n",
    "        # logits = self.last_linear(x)\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(-1, self.args.vocab_size), targets.view(-1))\n",
    "            return logits, loss\n",
    "\n",
    "        else:\n",
    "            return logits\n",
    "\n",
    "model = RopeModel(Args)\n",
    "model.to(Args.device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "train(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_size : 32\n",
       "context_window : 16\n",
       "n_layers : 18\n",
       "n_heads : 8\n",
       "vocab_size : 98\n",
       "d_model : 128\n",
       "epochs : 10000\n",
       "log_interval : 10\n",
       "max_seq_len : 512\n",
       "ffn_dim_multiplier : None\n",
       "multiple_of : 256\n",
       "device : cuda"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nLook out caughts. She saw a friends said.\\n\"Ow, let\\'s get. You are wise how the duck was wheir new th',\n",
       " '\\nDaddy, a time, there was a cown coud truck. He yells her friends were happy to strong time in the wa',\n",
       " '\\nBut, this knew his family ran towers, Samong in the sky with her and even said it we see his wan and',\n",
       " '\\nJack and SuiHa thought I for them. They knew the driver actor. \"I think you appoo!\"\\nBen aid, so, the',\n",
       " '\\n<|endoftext|>\\nOnce upon a time, there was a woman licked each other. She saw in an earch and.\\n<|endo']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate(model, args=Args, max_new_tokens=30):\n",
    "    idx = torch.zeros(5, 1).long().to(args.device)\n",
    "    for _ in range(max_new_tokens):\n",
    "        # call the model\n",
    "        logits = model(idx[:, -args.context_window:])\n",
    "        last_time_step_logits = logits[\n",
    "            :, -1, :\n",
    "        ]  # all the batches (1), last time step, all the logits\n",
    "        p = F.softmax(last_time_step_logits, dim=-1)  # softmax to get probabilities\n",
    "        idx_next = torch.multinomial(\n",
    "            p, num_samples=1\n",
    "        )  # sample from the distribution to get the next token\n",
    "        idx = torch.cat([idx, idx_next], dim=-1)  # append to the sequence\n",
    "    return [decode(x) for x in idx.tolist()]\n",
    "\n",
    "generate(model, Args, max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.zeros(5, 1).long()\n",
    "model_input = idx[:, -Args.context_window:]\n",
    "model_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of RopeModel(\n",
       "  (embedding): Embedding(98, 128)\n",
       "  (layers): ModuleList(\n",
       "    (0-17): 18 x EncoderBlock(\n",
       "      (attention): SelfAttention(\n",
       "        (wq): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (wk): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (wv): Linear(in_features=128, out_features=128, bias=False)\n",
       "        (wo): Linear(in_features=128, out_features=128, bias=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (w1): Linear(in_features=128, out_features=512, bias=False)\n",
       "        (w2): Linear(in_features=512, out_features=128, bias=False)\n",
       "        (w3): Linear(in_features=128, out_features=512, bias=False)\n",
       "      )\n",
       "      (attention_norm): RMSNorm()\n",
       "      (ffn_norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (output): Linear(in_features=128, out_features=98, bias=False)\n",
       ")>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Args.context_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "torch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
